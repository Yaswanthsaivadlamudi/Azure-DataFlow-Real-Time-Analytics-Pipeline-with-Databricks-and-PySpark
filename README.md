# Azure DataFlow: Real-Time Analytics Pipeline with Databricks and PySpark

## ğŸ“Œ Overview
This project demonstrates the creation of a real-time, parameterized, end-to-end data pipeline using **Azure Data Factory**, **Databricks**, **PySpark**, and other modern data engineering tools. The pipeline processes Netflix's public dataset and implements the **Medallion Architecture (Bronze, Silver, Gold layers)** for efficient data ingestion, transformation, and analytics.

The solution is designed to handle incremental data ingestion, dynamic parameterization, and real-time analytics while integrating seamlessly with visualization tools like **Power BI**.

---

## ğŸš€ Features
- **Dynamic ETL Pipelines:** Parameterized workflows using Azure Data Factory for real-time data validation.
- **Incremental Data Ingestion:** Implemented with Databricks Autoloader to handle streaming and batch data.
- **Medallion Architecture:**
  - **Bronze Layer:** Raw data ingestion.
  - **Silver Layer:** Cleaned and transformed datasets.
  - **Gold Layer:** Aggregated datasets for business intelligence.
- **Real-Time Analytics:** Delta Live Tables for efficient ETL workflows.
- **Visualization Integration:** Power BI dashboards for reporting and insights.

---

## ğŸ§± Architecture: Medallion Layers
- **Bronze Layer:** Raw data storage (unprocessed)
- **Silver Layer:** Cleaned and enriched data
- **Gold Layer:** Business-ready aggregated datasets

---

## ğŸ› ï¸ Tools and Technologies

| Technology         | Purpose                                       |
|--------------------|-----------------------------------------------|
| Azure Data Factory | Orchestrating ETL pipelines                   |
| Databricks         | Data transformation using PySpark             |
| PySpark            | Big data processing                           |
| Delta Lake         | Real-time analytics with Delta Live Tables    |
| Azure Data Lake    | Scalable cloud storage                        |
| Power BI           | Visualization of processed data               |

---

## ğŸ“‚ Dataset
This project uses **Netflix's public dataset** available on GitHub. The dataset includes information about movies, TV shows, genres, release years, etc.

---

## ğŸ”„ Pipeline Workflow

### ğŸ“¥ Data Ingestion
- Source data is ingested from GitHub into **Azure Data Lake Storage (ADLS)** using Azure Data Factory.
- Incremental loading is handled by **Databricks Autoloader**.

### ğŸ§¹ Data Transformation
- **PySpark scripts** in Databricks clean and transform the raw data into **Delta Live Tables**.
- Medallion architecture is applied to process the data through **Bronze â†’ Silver â†’ Gold** layers.

### ğŸ“Š Data Analytics & Visualization
- The **Gold layer** aggregates are used to create **Power BI dashboards** for real-time insights.

---


---

## ğŸ§  Key Learnings
- Implementing a scalable Medallion architecture for real-time analytics.
- Automating ETL workflows using Azure Data Factory and Databricks.
- Leveraging PySpark for efficient big data transformations.
- Integrating cloud-based pipelines with business intelligence tools like Power BI.

---

## ğŸ”§ Future Enhancements
- Add support for additional datasets from other sources (e.g., REST APIs).
- Implement CI/CD pipelines using Azure DevOps or GitHub Actions for deployment automation.
- Extend pipeline capabilities to include machine learning model integration.


